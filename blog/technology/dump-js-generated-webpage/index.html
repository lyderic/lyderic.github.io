<!DOCTYPE html>
<html lang="fr-FR" dir="ltr">
<head>
  <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>Dump Javascript Generated Webpage | De Mundis Lyderici</title>
<link rel="stylesheet" href="/css/normalize.css" />
<link rel="stylesheet" href="https://unpkg.com/sakura.css/css/sakura.css" media="screen" />
<link rel="stylesheet" href="https://unpkg.com/sakura.css/css/sakura-dark.css" media="screen and (prefers-color-scheme: dark)" />


<link rel="stylesheet" href="/css/custom.min.css">

</head>
<body>
  <header>
    <nav>
	<div>
		<a href="/">De Mundis Lyderici</a>
	</div>
	<div>
		|
			<a href="/blog/observations/">Observations</a> |
			<a href="/blog/technology/">Technology</a> |
			<a href="/livres/">Mes livres</a> |
	</div>
</nav>


<hr />

  </header>
  <main>
    

  <h3>Dump Javascript Generated Webpage</h3>

  
	

	<div style="text-align:right;font-style:italic;">
		<time datetime="2024-03-25T11:47:08&#43;01:00">25 mars 2024</time>
	</div>

	<hr />

	<div style="text-align:justify;margin-top:2em;">
  <p>With <code>curl</code> or <code>wget</code>, it is easy enough to dump the content of a webpage. However, some webpages are generated by Javascript and <code>curl</code>ing them results in not HTML but JS garbage.</p>
<p>There is a way around this: use <em>chromium</em> to dump the page. It will properly parse and execute the JS and render parsable HTML. The command is:</p>
<pre><code>chromuium --headless --incognito --dump-dom https://&lt;url&gt;
</code></pre>

	</div>
  



  </main>
  <footer>
    <p style="font-size:small;font-style:italic;text-align:right;">&copy; Lyd√©ric Landry, Luxembourg 2024


<script src="/js/main.js"></script>

  </footer>
</body>
</html>
